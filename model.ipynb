{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from train import Trainer, GAN_Trainer\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from UNet_model import UNet\n",
    "from UNet_GAN_model import UNetGen, UNetDis\n",
    "from GAN_model import NetGen, NetDis\n",
    "from ResNet_model import ResNet\n",
    "\n",
    "from colorize_data import ColorizeData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "paths = np.array([])\n",
    "training_set_path = os.path.join(current_directory, 'Dataset', 'training_set')\n",
    "for p in os.listdir(training_set_path):\n",
    "    new_path = os.path.join(training_set_path,p)\n",
    "    n_paths = np.array(glob.glob( new_path+ \"/*.jpg\"))\n",
    "    paths = np.concatenate([paths,n_paths])\n",
    "\n",
    "val_paths = np.array([])\n",
    "validation_set_path = os.path.join(current_directory, 'Dataset', 'validation_set')\n",
    "for p in os.listdir(validation_set_path):\n",
    "    new_path = os.path.join(validation_set_path,p)\n",
    "    n_paths = np.array(glob.glob( new_path+ \"/*.jpg\"))\n",
    "    val_paths = np.concatenate([paths,n_paths])\n",
    "\n",
    "train_indices = np.random.permutation(len(paths))\n",
    "train_paths = paths[train_indices]\n",
    "val_indices = np.random.permutation(len(val_paths))\n",
    "val_paths = val_paths[val_indices]\n",
    "\n",
    "# trainer = GAN_Trainer(train_paths, val_paths, epochs = 1, batch_size = 64, learning_rate = 0.01, num_workers = 2)\n",
    "# trainer.train(NetG=UNetGen(), NetD=UNetDis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [14:29<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.290220847649452\n"
     ]
    }
   ],
   "source": [
    "trainers = { Trainer:[[ResNet(), 'ResNet'], [UNet(), 'UNet']],GAN_Trainer:[[NetGen(),NetDis(),\"GAN\"],[UNetGen(),UNetDis(), \"UNetGAN\"]]}\n",
    "Losses = {}\n",
    "\n",
    "for t in trainers.keys():\n",
    "    for n in trainers[t]:\n",
    "        trainer = t(train_paths, val_paths, epochs = 10, batch_size = 16, learning_rate = 0.01, num_workers = 2)\n",
    "        loss, val_loss = trainer.train(*n)\n",
    "        Losses[n[-1]]= [loss, val_loss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResNet': [[0.8162988026936849,\n",
       "   0.5508615473906199,\n",
       "   0.3843180040518443,\n",
       "   0.3461948136488597,\n",
       "   0.3016207814216614],\n",
       "  [8370.706176757812,\n",
       "   1105.971206665039,\n",
       "   34.883737087249756,\n",
       "   6.462254047393799,\n",
       "   2.54803603887558]],\n",
       " 'UNet': [[0.6264670590559641,\n",
       "   0.4051589369773865,\n",
       "   0.3544735610485077,\n",
       "   0.2899746497472127,\n",
       "   0.2556848078966141],\n",
       "  [1.0973852574825287,\n",
       "   1.031692087650299,\n",
       "   0.8299153596162796,\n",
       "   0.6190952807664871,\n",
       "   0.3958797827363014]],\n",
       " 'GAN': [[[0.6193176110585531, 13.864546457926432],\n",
       "   [33.333333333333336, 31.934542338053387],\n",
       "   [33.333333333333336, 13.763161977132162],\n",
       "   [33.333333333333336, 13.780946095784506],\n",
       "   [33.333333333333336, 13.586840311686197]],\n",
       "  [[0.7420367399851481, 33.42511240641276],\n",
       "   [33.333333333333336, 30.811915079752605],\n",
       "   [33.333333333333336, 14.050852457682291],\n",
       "   [33.333333333333336, 13.096725463867188],\n",
       "   [33.333333333333336, 12.958033243815104]]],\n",
       " 'UNetGAN': [[[0.7325641314188639, 8.508634567260742],\n",
       "   [33.333333333333336, 32.683441162109375],\n",
       "   [33.333333333333336, 15.454026540120443],\n",
       "   [33.333333333333336, 11.040231068929037],\n",
       "   [33.333333333333336, 5.519066492716472]],\n",
       "  [[0.9821084340413412, 37.94142405192057],\n",
       "   [33.333333333333336, 25.16094970703125],\n",
       "   [33.333333333333336, 12.541241963704428],\n",
       "   [33.333333333333336, 7.036030451456706],\n",
       "   [33.333333333333336, 4.954316775004069]]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('losses.json', 'w') as f:\n",
    "    json.dump(Losses, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
